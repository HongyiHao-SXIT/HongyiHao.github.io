<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <link rel="icon" type="image/png" href="images/HongMing_Logo.png">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Design Credits: Jon Barron and Deepak Pathak and Abhishek Kar and Saurabh Gupta*/
    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    body,
    td,
    th {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 400
    }

    heading {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 17px;
      font-weight: 600
    }

    hr {
      border: 0;
      height: 1px;
      background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
      margin: 20px 0;
    }

    strong {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 600
    }

    strongred {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      color: red;
      font-size: 16px
    }

    sectionheading {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 22px;
      font-weight: 600
    }

    pageheading {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 38px;
      font-weight: 400
    }

    .ImageBorder {
      border-width: 1px;
      border-color: Black;
    }

    .content-section {
      margin-bottom: 30px;
    }

    .honor-item,
    .internship-item {
      margin-bottom: 8px;
    }

    .paper-links {
      margin-top: 8px;
      margin-bottom: 8px;
    }
  </style>
  <link rel="shortcut icon" href="images/apple-touch-ri-logo-white-120x120.png">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Hongyi Hao</title>
  <meta name="Hongyi Hao's Homepage" content="Hongyi Hao's Personal Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic'
    rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="900" border="0" align="center" cellspacing="0" cellpadding="20">
    <tr>
      <td>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <p align="center">
            <pageheading>Hongyi Hao 「郝泓毅」</pageheading><br>
          </p>

          <tr>
            <td width="30%" valign="top">
              <a href="images/HongyiHao_White.jpg">
                <img src="images/HongyiHao_White.jpg" width="100%"
                  style="border-radius:15px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
              </a>
              <p align=center style="margin-top:15px;">
                | <a href="data/HongyiHao_CV.pdf">CV</a> |
                <a href="mailto:Lanyi_adict@outlook.com">Email</a> |
                <a href="https://scholar.google.com/">Google Scholar</a> |
                <br />
                | <a href="https://github.com/HongyiHao-SXIT">Github</a> |
                <a href="https://space.bilibili.com/291940264">Bilibili</a> |
              </p>
            </td>
            <td width="70%" valign="top" align="justify">
              <p>I am a senior undergraduate student majoring in computer science at <a
                  href="http://www.sxit.edu.cn">Shanxi Institute of Technology</a>. I specialize in <b>Reinforcement
                  Learning</b> and <b>Robotics</b>.</p>

              <p><strong>Goal:</strong> Develop advanced robotic systems that can revolutionize various industries and
                improve people's lives.</p>

              <p><strong>Focus:</strong> How to improve the autonomy, safety, and adaptability of robots through
                innovative algorithms? How to combine artificial intelligence and machine learning to enable robots to
                learn and make intelligent decisions from different real-world scenarios?</p>

              <p><strong>Method:</strong> Research and implement state-of-the-art machine learning algorithms, and
                conduct extensive experiments to optimize robot performance.</p>

              <p><strong>Robots:</strong> I am passionate about exploring the potential of humanoid robots. My goal is
                to develop humanoid robots that can perform complex tasks in challenging environments.</p>

              <p>Email: Lanyi_adict[AT]outlook.com</p>
            </td>
          </tr>
        </table>

        <hr />

        <!-- Personal Honors Section -->
        <div class="content-section">
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
            <tr>
              <td>
                <sectionheading>Personal Honors</sectionheading>
              </td>
            </tr>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
            <tr>
              <td>
                <ul>
                  <li class="honor-item">Special Prize in the 19th "Challenge Cup" Shanxi Province College Students'
                    Extracurricular Academic and Technological Works Competition (Provincial Level)</li>
                  <li class="honor-item">Silver Award in China International College Students' Innovation and
                    Entrepreneurship Competition (2025) Shaanxi Regional Final - Higher Education Main Track</li>
                  <li class="honor-item">Second Prize in the "Youth Innovation and Entrepreneurship Competition of
                    Shanxi Central Urban Agglomeration 'Creating Youth'" (Provincial Level)</li>
                  <li class="honor-item">Third Prize in the "Zhongkong Xinda Cup" North China Five Provinces and Hong
                    Kong, Macao and Taiwan College Students Computer Programming Competition (Provincial Level)</li>
                  <li class="honor-item">Second Prize in the 2025 Shanxi Province "Five Small" Innovation Competition
                    (Provincial Level)</li>
                  <li class="honor-item">Excellence Award in the "Maker China" Shanxi Small and Medium-sized Enterprise
                    Innovation and Entrepreneurship Competition (Provincial Level)</li>
                  <li class="honor-item">Second-class Department Scholarship in 2022-2023 Academic Year</li>
                  <li class="honor-item">Third-class Department Scholarship in 2023-2024 Academic Year</li>
                  <li class="honor-item">Individual Scholarship in 2023-2024 Academic Year</li>
                </ul>
              </td>
            </tr>
          </table>
        </div>

        <hr />

        <!-- Publications Section -->
        <div class="content-section">
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
            <tr>
              <td>
                <sectionheading>Publications</sectionheading>
              </td>
            </tr>
          </table>

          <!-- VoteRFID Paper -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
            <tr>
              <td width="40%" valign="top" align="center">
                <img src="images/VoteRFID/VoteRFID.png" alt="VoteRFID Project" width="90%"
                  style="padding-top:0px;padding-bottom:0px;border-radius:15px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
              </td>
              <td width="60%" valign="top">
                <p>
                  <a href="#VoteRFID" id="VoteRFID">
                    <heading>VoteRFID: Multi-Target Rotation Recognition Algorithm Based on Phase Encoding via Markov
                      Transition Field</heading>
                  </a>
                  <br>
                </p>
                <p>Zhonghao Wang, <b>Hongyi Hao</b>, Biaokai Zhu, et al.<br>IEEE ISPA 2025 (CCF Recommended
                  Conference)<br></p>

                <div class="paper" id="VoteRFID_paper">
                  <div class="paper-links">
                    <a href="projects/voterfid.html">webpage</a> |
                    <a href="papers/voterfid.pdf">pdf</a> |
                    <a href="javascript:toggleblock('voterfid_abs')">abstract</a> |
                    <a shape="rect" href="javascript:togglebib('VoteRFID_paper')" class="togglebib">bibtex</a> |
                    <a href="https://arxiv.org/abs/XXXX.XXXXX">arXiv</a>
                  </div>

                  <div id="voterfid_abs" style="display:none">
                    <p align="justify"><i>[Abstract will be added later]</i></p>
                  </div>

                  <div id="VoteRFID_paper_bib" style="display:none">
                    <pre xml:space="preserve">
@inproceedings{wang2025voterfid,
  title={VoteRFID: Multi-Target Rotation Recognition Algorithm Based on Phase Encoding via Markov Transition Field},
  author={Wang, Zhonghao and Hao, Hongyi and Zhu, Biaokai and others},
  booktitle={The 23rd IEEE International Symposium on Parallel and Distributed Processing with Applications (ISPA 2025)},
  year={2025},
  organization={IEEE}
}
            </pre>
                  </div>
                </div>
              </td>
            </tr>
          </table>

          <!-- mmWave Paper -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
            <tr>
              <td width="40%" valign="top" align="center">
                <img src="images/mmWave/mmWave.png" alt="mmWave Liquid Sensing Project" width="90%"
                  style="padding-top:0px;padding-bottom:0px;border-radius:15px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
              </td>
              <td width="60%" valign="top">
                <p>
                  <a href="#mmWave" id="mmWave">
                    <heading>Temperature-Aware Liquid Sensing with mm-Wave Radar</heading>
                  </a>
                  <br>
                </p>
                <p>Zeyu Fan, Zhaokui Wang, <b>Hongyi Hao</b>, et al.<br>IEEE ISPA 2025 (CCF Recommended Conference)<br>
                </p>

                <div class="paper" id="mmwave_paper">
                  <div class="paper-links">
                    <a href="projects/mmwave.html">webpage</a> |
                    <a href="papers/mmwave.pdf">pdf</a> |
                    <a href="javascript:toggleblock('mmwave_abs')">abstract</a> |
                    <a shape="rect" href="javascript:togglebib('mmwave_paper')" class="togglebib">bibtex</a> |
                    <a href="https://arxiv.org/abs/XXXX.XXXXX">arXiv</a>
                  </div>

                  <div id="mmwave_abs" style="display:none">
                    <p align="justify"><i>[Abstract will be added later]</i></p>
                  </div>

                  <div id="mmwave_paper_bib" style="display:none">
                    <pre xml:space="preserve">
@inproceedings{fan2025mmwave,
  title={Temperature-Aware Liquid Sensing with mm-Wave Radar},
  author={Fan, Zeyu and Wang, Zhaokui and Hao, Hongyi and others},
  booktitle={The 23rd IEEE International Symposium on Parallel and Distributed Processing with Applications (ISPA 2025)},
  year={2025},
  organization={IEEE}
}
            </pre>
                  </div>
                </div>
              </td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
            <tr>
              <td width="40%" valign="top" align="center">
                <img src="images/EEGAuth/EEGAuth.png" alt="EEGAuth Project" width="90%"
                  style="padding-top:0px;padding-bottom:0px;border-radius:15px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
              </td>
              <td width="60%" valign="top">
                <p>
                  <a href="#EEGAuth" id="EEGAuth">
                    <heading>EEGAuth: A Secure and Lightweight EEG-Based System Integrating Authentication and Key
                      Generation</heading>
                  </a>
                  <br>
                </p>
                <p>Xun Han, Jun Xiao, Yifan Liu, Ruilin Zhang, Kaibiao Zhu, <b>Hongyi Hao</b>, Youqi Li, Fan Li, Qian
                  Zhang<br>
                  <i>IEEE Internet of Things Journal (IEEE IoT-J), 2025</i><br>
                </p>

                <div class="paper" id="EEGAuth_paper">
                  <div class="paper-links">
                    <a href="projects/eegauth.html">webpage</a> |
                    <a href="papers/eegauth.pdf">pdf</a> |
                    <a href="javascript:toggleblock('eegauth_abs')">abstract</a> |
                    <a shape="rect" href="javascript:togglebib('EEGAuth_paper')" class="togglebib">bibtex</a> |
                    <a href="https://ieeexplore.ieee.org/">IEEE Xplore</a>
                  </div>

                  <div id="eegauth_abs" style="display:none">
                    <p align="justify"><i>[Abstract will be added later]</i></p>
                  </div>

                  <div id="EEGAuth_paper_bib" style="display:none">
                    <pre xml:space="preserve">
@article{han2025eegauth,
  title={EEGAuth: A Secure and Lightweight EEG-Based System Integrating Authentication and Key Generation},
  author={Han, Xun and Xiao, Jun and Liu, Yifan and Zhang, Ruilin and Zhu, Kaibiao and Hao, Hongyi and Li, Youqi and Li, Fan and Zhang, Qian},
  journal={IEEE Internet of Things Journal},
  year={2025},
  publisher={IEEE}
}
            </pre>
                  </div>
                </div>
              </td>
            </tr>
          </table>

          <!-- Multi-Agent Paper -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
            <tr>
              <td width="40%" valign="top" align="center">
                <img src="images/MADRL/MADRL.png" alt="Multi-Agent Reinforcement Learning Project" width="90%"
                  style="padding-top:0px;padding-bottom:0px;border-radius:15px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
              </td>
              <td width="60%" valign="top">
                <p>
                  <a href="#MultiAgent" id="MultiAgent">
                    <heading>Research and Application of Multi-Agent Cooperative Decision Algorithm Based on Deep
                      Reinforcement Learning</heading>
                  </a>
                  <br>
                </p>
                <p>Hongyi Hao*<br>ICDACAI 2025<br></p>

                <div class="paper" id="multiagent_paper">
                  <div class="paper-links">
                    <a href="projects/multi_agent.html">webpage</a> |
                    <a href="papers/multi_agent.pdf">pdf</a> |
                    <a href="javascript:toggleblock('multiagent_abs')">abstract</a> |
                    <a shape="rect" href="javascript:togglebib('multiagent_paper')" class="togglebib">bibtex</a> |
                    <a href="https://arxiv.org/abs/XXXX.XXXXX">arXiv</a>
                  </div>

                  <div id="multiagent_abs" style="display:none">
                    <p align="justify">
                      <i>In complex dynamic environment, there are some problems in multi-agent collaborative
                        decision-making, such as non-stationarity, credit distribution deviation and imperfect
                        topological relationship modeling. In this article, the deep reinforcement learning (DRL)
                        algorithm Att-GNN-MARL, which combines attention mechanism and GNN, is proposed to improve the
                        cooperative efficiency and strategic stability of multi-agent system (MAS). Based on the
                        centralized training decentralized execution (CTDE) framework, this study uses graph neural
                        network (GNN) to model the spatial connection of agents, introduces attention mechanism to
                        enhance the perception of key neighbors, and designs a counterfactual reward correction
                        mechanism to optimize local credit allocation. In the collaborative control scenario of urban
                        traffic signals, the experiments based on real road network on SUMO simulation platform show
                        that the proposed algorithm reduces the average waiting time of vehicles to 54.3 seconds during
                        rush hours, which is 22.3% less than that of QMIX. The total traffic volume reached 24,108
                        vehicles, which was significantly better than the comparison method. The number of rounds of
                        strategy convergence is 640, and the learning efficiency is good. The research shows that the
                        cooperative learning mechanism combining structural perception and dynamic attention can improve
                        the overall performance of MAS in highly coupled tasks to some extent.</i>
                    </p>
                  </div>

                  <div id="multiagent_paper_bib" style="display:none">
                    <pre xml:space="preserve">
@article{hao2025madrl,
  title={Research and Application of Multi-Agent Cooperative Decision Algorithm Based on Deep Reinforcement Learning},
  author={Hongyi Hao},
  journal={ICDACAI 2025},
  year={2025}
}
            </pre>
                  </div>
                </div>
              </td>
            </tr>
          </table>

          <!-- CRLC Paper -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
            <tr>
              <td width="40%" valign="top" align="center">
                <img src="images/CRLC/CRLC.jpg" alt="Cross-embodied RL Control Project" width="90%"
                  style="padding-top:0px;padding-bottom:0px;border-radius:15px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
              </td>
              <td width="60%" valign="top">
                <p>
                  <a href="#CRLC" id="CRLC">
                    <heading>Cross-embodied Reinforcement Learning Control Method for Quadruped Robots on Complex
                      Terrain</heading>
                  </a>
                  <br>
                </p>
                <p>Hongyi Hao*<br>2025 International Conference on Robotics and Smart Systems (ICRSS 2025)<br></p>

                <div class="paper" id="crlc_paper">
                  <div class="paper-links">
                    <a href="projects/crlc.html">webpage</a> |
                    <a href="papers/crlc.pdf">pdf</a> |
                    <a href="javascript:toggleblock('crlc_abs')">abstract</a> |
                    <a shape="rect" href="javascript:togglebib('crlc_paper')" class="togglebib">bibtex</a> |
                    <a href="https://arxiv.org/abs/XXXX.XXXXX">arXiv</a>
                  </div>

                  <div id="crlc_abs" style="display:none">
                    <p align="justify">
                      <i>With the widespread application of quadruped robots in complex terrains, achieving efficient
                        and stable motion control in these changing environments has become a key issue. Traditional
                        control methods often rely on pre-set control rules or models, which struggle to maintain
                        consistency across different platforms and complex terrain conditions. This paper proposes a
                        control method for quadruped robots based on cross-embodied reinforcement learning (C-ERL),
                        aiming to address the robot's adaptability to diverse challenges in complex terrain. By
                        introducing a reinforcement learning framework and an adaptive reward function, this method not
                        only optimizes the robot's motion control on flat terrain, slopes, rocky areas, and loose
                        gravel, but also enables cross-platform transfer of control strategies. Experimental results
                        show that using this method, the quadruped robot achieves an 8% increase in average speed, a 15%
                        improvement in posture stability, a 12% reduction in specific energy consumption, and a task
                        completion rate exceeding 90% across various complex terrains. In terms of cross-platform
                        transfer, the robot's overall score varies less than 5% between platforms, demonstrating strong
                        cross-embodied adaptability. This study provides a new solution for the efficient control of
                        quadruped robots in dynamic and complex environments and lays a foundation for the further
                        development of cross-embodied control technology.</i>
                    </p>
                  </div>

                  <div id="crlc_paper_bib" style="display:none">
                    <pre xml:space="preserve">
@inproceedings{hao2025crlc,
  title={Cross-embodied Reinforcement Learning Control Method for Quadruped Robots on Complex Terrain},
  author={Hao, Hongyi},
  booktitle={Proceedings of the 2025 International Conference on Robotics and Smart Systems},
  pages={1--8},
  year={2025},
  organization={IEEE}
}
            </pre>
                  </div>
                </div>
              </td>
            </tr>
          </table>

          <!-- ECHOES Paper -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
            <tr>
              <td width="40%" valign="top" align="center">
                <img src="images/ECHOES/ECHOES.png" alt="ECHOES Project" width="90%"
                  style="padding-top:0px;padding-bottom:0px;border-radius:15px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
              </td>
              <td width="60%" valign="top">
                <p>
                  <a href="#ECHOES" id="ECHOES">
                    <heading>ECHOES: input sensing and rEconstruCtion model utilizing CNN and LSTM witH mObilE Sensor
                      data</heading>
                  </a>
                  <br>
                </p>
                <p>Hongyi Hao*<br>ICICC 2025<br></p>

                <div class="paper" id="echoes_paper">
                  <div class="paper-links">
                    <a href="projects/echoes.html">webpage</a> |
                    <a href="papers/echoes.pdf">pdf</a> |
                    <a href="javascript:toggleblock('echoes_abs')">abstract</a> |
                    <a shape="rect" href="javascript:togglebib('echoes_paper')" class="togglebib">bibtex</a> |
                    <a href="https://arxiv.org/abs/XXXX.XXXXX">arXiv</a>
                  </div>

                  <div id="echoes_abs" style="display:none">
                    <p align="justify">
                      <i>The widespread integration of sensors such as accelerometers and gyroscopes in smartphones has
                        significantly enhanced user experience, but also introduced new vulnerabilities exploitable by
                        side-channel attacks. These attacks can infer user input by analyzing motion patterns generated
                        during touch interactions. To mitigate this threat and improve input recognition accuracy, we
                        propose ECHOES, a side-channel analysis framework designed to recover user input on touchscreen
                        keyboards. ECHOES comprises two key modules: (i) a sensing module that collects inertial sensor
                        data and virtual memory change patterns, employing convolutional neural networks to detect the
                        user's motion state and classify touch interactions into predefined keyboard regions; and (ii) a
                        language inference module that leverages the click region sequence and natural language
                        processing to reconstruct the user's intended input. To further improve localization under
                        spatial ambiguity, the keyboard is partitioned into five regions to constrain candidate outputs.
                        Experimental results demonstrate that ECHOES achieves 94.01% accuracy in motion state
                        recognition and 91.63% accuracy in input restoration, underscoring its potential for exposing
                        security risks in mobile input systems.</i>
                    </p>
                  </div>

                  <div id="echoes_paper_bib" style="display:none">
                    <pre xml:space="preserve">
@article{hao2025echoes,
  title={ECHOES: input sensing and rEconstruCtion model utilizing CNN and LSTM witH mObilE Sensor data},
  author={Hongyi Hao},
  journal={ICICC 2025},
  year={2025}
}
            </pre>
                  </div>
                </div>
              </td>
            </tr>
          </table>

          <!-- Slope Stability Paper -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
            <tr>
              <td width="40%" valign="top" align="center">
                <img src="images/SAPSC/SAPSC.png" alt="Slope Stability Analysis Project" width="90%"
                  style="padding-top:0px;padding-bottom:0px;border-radius:15px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
              </td>
              <td width="60%" valign="top">
                <p>
                  <a href="#SlopeStability" id="SlopeStability">
                    <heading>Stability Analysis of Polygonal Slopes Considering Spatial Variability of Soil Parameters
                    </heading>
                  </a>
                  <br>
                </p>
                <p>Hongyi Hao*<br>ICICDA 2025<br></p>

                <div class="paper" id="slope_paper">
                  <div class="paper-links">
                    <a href="projects/slope_stability.html">webpage</a> |
                    <a href="papers/slope_stability.pdf">pdf</a> |
                    <a href="javascript:toggleblock('slope_abs')">abstract</a> |
                    <a shape="rect" href="javascript:togglebib('slope_paper')" class="togglebib">bibtex</a> |
                    <a href="https://arxiv.org/abs/XXXX.XXXXX">arXiv</a>
                  </div>

                  <div id="slope_abs" style="display:none">
                    <p align="justify">
                      <i>Slope stability analysis is a critical issue in geotechnical engineering. Traditional
                        mechanical models are computationally intensive and inefficient, while incorporating the spatial
                        variability of soil/rock parameters can significantly improve the accuracy of analysis results.
                        To address this, this study proposes an efficient and accurate prediction model for slope safety
                        factors by integrating spatial variability of geotechnical parameters with machine learning
                        algorithms. The research employs Latin Hypercube Sampling (LHS) and random field simulation to
                        generate soil parameters with spatial variability, followed by predictive modeling using the Cat
                        Boost (Categorical Boosting) algorithm. Results demonstrate that the Cat Boost model outperforms
                        Support Vector Machine (SVM) and Random Forest (RF) models across multiple metrics, including
                        accuracy (93% on the test set), precision, recall, and AUC. The proposed method, combining
                        spatial variability with machine learning, offers a more precise and efficient approach to slope
                        stability assessment.</i>
                    </p>
                  </div>

                  <div id="slope_paper_bib" style="display:none">
                    <pre xml:space="preserve">
@article{hao2025slope,
  title={Stability Analysis of Polygonal Slopes Considering Spatial Variability of Soil Parameters},
  author={Hongyi Hao},
  journal={ICICDA 2025},
  year={2025}
}
            </pre>
                  </div>
                </div>
              </td>
            </tr>
          </table>

          <!-- YOLO Pruning Paper -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
            <tr>
              <td width="40%" valign="top" align="center">
                <img src="images/SPE/SPE.png" alt="YOLO Pruning Project" width="90%"
                  style="padding-top:0px;padding-bottom:0px;border-radius:15px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
              </td>
              <td width="60%" valign="top">
                <p>
                  <a href="#YOLOPruning" id="YOLOPruning">
                    <heading>Structured Pruning for Efficient YOLO11 Deployment: A Comparative Study of LAMP and SPPF
                      Algorithms</heading>
                  </a>
                  <br>
                </p>
                <p>Hongyi Hao*<br>2025 International Conference on Mechanical Automation and Electronic Engineering
                  (ICMAEE 2025)<br></p>

                <div class="paper" id="yolo_paper">
                  <div class="paper-links">
                    <a href="projects/yolo_pruning.html">webpage</a> |
                    <a href="papers/yolo_pruning.pdf">pdf</a> |
                    <a href="javascript:toggleblock('yolo_abs')">abstract</a> |
                    <a shape="rect" href="javascript:togglebib('yolo_paper')" class="togglebib">bibtex</a> |
                    <a href="https://arxiv.org/abs/XXXX.XXXXX">arXiv</a>
                  </div>

                  <div id="yolo_abs" style="display:none">
                    <p align="justify">
                      <i>This study explores the integration of two structured pruning techniques - Layer Adaptive
                        Magnitude Pruning (LAMP) and Spatial Pyramid Pooling Framework (SPPF) - into YOLO-based object
                        detection models to enhance their deployment efficiency on edge computing platforms with limited
                        computational resources. LAMP achieves high compression rates by dynamically adjusting the
                        sparsity of each layer, making it particularly suitable for real-time applications such as
                        medical imaging (e.g., rib fracture detection) and traffic monitoring, providing an effective
                        solution for mobile terminal deployment. Meanwhile, SPPF improves multi-scale feature fusion and
                        enhances detection robustness in complex environments (such as forestry pest identification and
                        satellite image analysis), significantly boosting the model's generalization ability.
                        Experimental evaluations across multiple domains including medical diagnosis, agricultural
                        monitoring, and intelligent transportation demonstrate that these two methods not only
                        significantly reduce model size and computational overhead but also maintain or even improve
                        detection accuracy. These findings offer practical insights for optimizing lightweight YOLO
                        variants, facilitating their widespread adoption in practical edge AI applications that
                        prioritize efficiency and accuracy.</i>
                    </p>
                  </div>

                  <div id="yolo_paper_bib" style="display:none">
                    <pre xml:space="preserve">
@article{hao2025yolo,
  title={Structured Pruning for Efficient YOLO11 Deployment: A Comparative Study of LAMP and SPPF Algorithms},
  author={Hongyi Hao},
  journal={ICMAEE 2025},
  year={2025}
}
            </pre>
                  </div>
                </div>
              </td>
            </tr>
          </table>
        </div>

        <hr />

        <!-- Internship Experiences Section -->
        <div class="content-section">
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
            <tr>
              <td>
                <sectionheading>Internship Experiences</sectionheading>
              </td>
            </tr>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
            <tr>
              <td>
                <ul>
                  <li class="internship-item"><strong>Nanjing Archmind Technology</strong> (2023.6 - 2023.8)</li>
                  <li class="internship-item"><strong>Nanjing Institute of Automation, Chinese Academy of
                      Sciences</strong> (2024.6 - Present)</li>
                  <li class="internship-item"><strong>Carnegie Mellon University</strong>, Distributed Machine Learning:
                    Foundations and Algorithms (2025.5.10 - 2025.8.8)</li>
                </ul>
              </td>
            </tr>
          </table>
        </div>

        <hr />

        <!-- Invention Patents and Software Works Section -->
        <div class="content-section">
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
            <tr>
              <td>
                <sectionheading>Invention Patents and Software Works</sectionheading>
              </td>
            </tr>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
            <tr>
              <td>
                <p><b>Invention Patents:</b></p>
                <ul>
                  <li>An Automatic Deviation-Correction Drilling Device for Tunnel Inner Walls (CN118361189B)</li>
                  <li>A Wall Bracket for Multi-Beam Visible Laser Devices (CN223388326U)</li>
                  <li>A Forced Centering Measurement Target Device (CN223389191U)</li>
                </ul>


                <p><b>Design Patents:</b></p>
                <ul>
                  <li>Security Robot (CN308942412S)</li>
                  <li>Tunnel RGB laser projection positioning device (CN309398989S)</li>
                </ul>

                <p><b>Software Copyrights:</b></p>
                <ul>
                  <li>Automatic Geological Radar Data Transmission System V1.0</li>
                  <li>Underground Space Concrete Quality Monitoring and Management System V1.0</li>
                  <li>Psychological Test Mini-Program V1.0 (2024SR0668850)</li>
                  <li>Tunnel Laser Projection Contour Model Making Software V1.0 (2024SR1961537)</li>
                  <li>Tunnel Laser Projection Coordinate Conversion Software V1.0</li>
                  <li>Programming Language Intelligent Learning Assistance Software V1.0 (2025SR0328689)</li>
                  <li>Computer Network Security Protection Software V1.0 (2025SR0380865)</li>
                  <li>Tunnel Drill Hole Coordinate Positioning Calculation Software V1.0 (2025SR2013678)</li>
                </ul>
              </td>
            </tr>
          </table>
        </div>

        <hr />

        <!-- Projects Section -->
        <div class="content-section">
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
            <tr>
              <td>
                <sectionheading>Projects</sectionheading>
              </td>
            </tr>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
            <tr>
              <td width="40%" valign="top" align="center">
                <img src="images/HongMing_Logo.png" alt="HongMing Intelligent Technology Team" width="70%"
                  style="padding-top:0px; padding-bottom:0px; border-radius:15px; height: auto; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
              </td>
              <td width="60%" valign="top">
                <p>
                  <a href="https://hongming-intelligent-technology.github.io/HongMing_Intelligent_Technology.github.io/"
                    id="HongMing">
                    <heading>Hongming Intelligent Technology Team 「弘茗智能科技团队」</heading>
                  </a>
                  <br>
                </p>

                <div class="paper" id="hongming_project">
                  <div class="paper-links">
                    <a
                      href="https://hongming-intelligent-technology.github.io/HongMing_Intelligent_Technology.github.io/">webpage</a>
                    |
                    <a href="https://github.com/Hongming-Intelligent-Technology">code</a>
                  </div>

                  <p align="justify">
                    <i>Founded by <b>Hao Hongyi</b> at the undergraduate level, we are committed to the research and
                      development of <b>advanced robotics</b> and <b>artificial intelligence systems</b>, and will also
                      conduct research in <b>software engineering, simulator, microelectronics, mechanical design,
                        Reinforcement Learning, Deep Learning</b> and other related directions according to personal
                      development direction.</i>
                  </p>
                </div>
              </td>
            </tr>
          </table>
        </div>

        <hr />

        <!-- Footer -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="2">
          <tr>
            <td>
              <br>
              <p align="right">
                Website template from <a href="http://www.cs.berkeley.edu/~barron/">here</a> and <a
                  href="http://www.cs.cmu.edu/~dpathak/">here</a>
              </p>
            </td>
          </tr>
        </table>

      </td>
    </tr>
  </table>

  <!-- JavaScript for hiding/showing content -->
  <script type="text/javascript">
    // Hide all bibliography sections by default
    function hideallbibs() {
      var bibs = document.getElementsByClassName('togglebib');
      for (var i = 0; i < bibs.length; i++) {
        var id = bibs[i].getAttribute('href').replace('javascript:togglebib(', '').replace(')', '');
        document.getElementById(id + '_bib').style.display = 'none';
      }
    }

    // Toggle block visibility
    function toggleblock(id) {
      var el = document.getElementById(id);
      if (el.style.display == 'none' || el.style.display == '') {
        el.style.display = 'block';
      } else {
        el.style.display = 'none';
      }
    }

    // Toggle bibliography visibility
    function togglebib(id) {
      var el = document.getElementById(id + '_bib');
      if (el.style.display == 'none' || el.style.display == '') {
        el.style.display = 'block';
      } else {
        el.style.display = 'none';
      }
    }

    // Initialize hidden elements
    hideallbibs();
  </script>

</body>

</html>